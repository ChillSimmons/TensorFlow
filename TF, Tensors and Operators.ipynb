{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 alpha - Tensors and Operators\n",
    "### This exercise covers (1) importing TensorFlow (2) creating/using tensors (3) GPU acceleration (4) tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TensorFlow\n",
    "#### Version 2.0 uses Eager Execution by default - enabling a more interactive TF Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "#### a Multidimensional Array, tf.Tensor Objects have a Data Type and Shape - TF Library offers many operations (tf.add, tf.matmul, etc.) that work on Tensors and native python types alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.square(2) + tf.square(3))      # operator overloading supported as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.Tensor has a Shape and Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2,3]])\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences between tf.Tensor and NumPy array - Tensors are Immutable (unchaning), and can be backed by Accelerator Memory (GPU, TPU, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Compatibility - Conversion\n",
    "#### TF operations automatically convert ndarrays to Tensors - NumPy operations explicitly convert Tensors to ndarrays using .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow operations convert NumPy arrays to Tensors automatically\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "\n",
      "And NumPy operations convert Tensors to NumPy arrays automatically\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "\n",
      "The .numpy() method explicitly converts a Tensor to a ndarray\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print('TensorFlow operations convert NumPy arrays to Tensors automatically')\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "print()\n",
    "print('And NumPy operations convert Tensors to NumPy arrays automatically')\n",
    "print(np.add(tensor, 1))\n",
    "print()\n",
    "print('The .numpy() method explicitly converts a Tensor to a ndarray')\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Acceleration\n",
    "#### Many TF operations are accelerated when using GPU for computation - TF decides automatically whether to use CPU or GPU for an operation, copying Tensors between memory if necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU available: \n",
      "False\n",
      "\n",
      "Is the Tensor on GPU #0: \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3,3])\n",
    "\n",
    "print('Is there a GPU available: '),\n",
    "print(tf.test.is_gpu_available())\n",
    "print()\n",
    "print('Is the Tensor on GPU #0: '),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Names\n",
    "#### Tensor.device provides qualified string name of the device hosting the tensor contents - Required for distributed execution of a TF program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Device Placement\n",
    "#### Placement - how individual operations are assigned on a device for execution - TF decides with no explicit guidance, or the tf.device Context Manager can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 230.56ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x) :\n",
    "    start = time.time()\n",
    "    for loop in range(10) :\n",
    "        tf.matmul(x, x)\n",
    "        \n",
    "    result = time.time()-start\n",
    "    \n",
    "    print('10 loops: {:0.2f}ms'.format(1000*result))\n",
    "    \n",
    "# force CPU execution\n",
    "\n",
    "print('On CPU:')\n",
    "with tf.device('CPU:0'):\n",
    "    x =tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith('CPU:0')\n",
    "    time_matmul(x)\n",
    "\n",
    "# force GPU execution, if available\n",
    "\n",
    "if tf.test.is_gpu_available() :\n",
    "    print('On GPU:')\n",
    "    with tf.device('GPU:0'):\n",
    "        x = tf.random.uniform([1000, 1000])\n",
    "        assert x.device.ednswith('GPU:)')\n",
    "        time_matmul(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "#### tf.data.Dataset is used to build Input Pipelines from simple, re-usable pieces that will feed the model\n",
    "### Create a Source - Dataset\n",
    "#### Created using factory functions like Dataset.from_tensors, Dataset.from_tensor_slices, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# create a CSV file\n",
    "\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f :\n",
    "    f.write('''Line 1\n",
    "    Line 2\n",
    "    Line 3\n",
    "    ''''')\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Transformations - like map, batch, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate the .Dataset Object - to loop over records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor([4 9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 1 36], shape=(2,), dtype=int32)\n",
      "\n",
      "\n",
      "Elements in ds_file:\n",
      "tf.Tensor([b'Line 1' b'    Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'    Line 3' b'    '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors :\n",
    "    print(x)\n",
    "print()\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
