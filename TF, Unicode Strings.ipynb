{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 alpha - Unicode Strings\n",
    "### Unicode - standard encoding system used to represent characters from nearly all languages\n",
    "* Models that handle Natural Language often work with languages with different character sets\n",
    "* Each character is encoded - using a unique integer Code Point between 0 - 0x10FFFF\n",
    "* Unicode String - sequence of 0 or more code points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, unicode_literals, print_function\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Type - tf.string \n",
    "* allows building tensors of byte strings\n",
    "* unicode strings - utf-8 encoded by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u'Thanks üòä')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.string - can hold byte strings of varying lengths - byte strings treated as atomic units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string length is Not included in the tensor dimensions\n",
    "\n",
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Unicode\n",
    "### 2 standard ways\n",
    "* String scalar - sequence of code points encoded using a known character encoding\n",
    "* int32 vector - each position contains a single code point\n",
    "\n",
    "### All 3 of the following represent the unicode string - \"ËØ≠Ë®ÄÂ§ÑÁêÜ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unicode string - represented as a UTF-8 encoded string scalar\n",
    "\n",
    "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unicode string - represented as a UTF-16-BE encoded string scalar\n",
    "\n",
    "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unicode string - represented as a vector of unicode code points\n",
    "\n",
    "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between Representations\n",
    "* tf.strings.unicode_decode - converts encoded string scalar - to vector of code points\n",
    "* tf.strings.unicode_encode - converts vector of code points - to encoded string scalar\n",
    "* tf.strings.unicode_transcode - converts encoded string scalar - to different encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8, input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8, input_encoding='UTF8', output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Dimensions\n",
    "#### When decoding multiple strings, of different lengths - result is a tf.RaggedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# batch of UTF-8 encoded unicode strings\n",
    "\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "             [u'h√Éllo', u'What is the weather tomorrow', u'G√∂√∂dnight', u'üòä']]\n",
    "\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8, input_encoding='UTF-8')\n",
    "\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.RaggedTensor can be used directly \n",
    "* or use tf.RaggedTensor.to_tensor - to convert it to a dense tf.Tensor with padding\n",
    "* or use tf.RaggedTensor.to_sparse - to convert it to tf.SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]], shape=(4, 28), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.Tensor may be used - when encoding multiple strings of the SAME length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=130, shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]],\n",
    "                         output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.RaggedTensor should be used - when encoding multiple strings with varying lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=132, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a tensor with multiple strings in padded, or sparse format:\n",
    "* convert it to a tf.RaggedTensor - before calling unicode_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=215, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "                         output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode Operations\n",
    "### Character Length - tf.strings.length operation has a parameter, unit\n",
    "* unit - defaults to \"BYTE\" - but can be set to other values - to determine number of unicode codepoints in each encoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "thanks = u'Thanks üòä'.encode('UTF-8')\n",
    "\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit = 'UTF8_CHAR').numpy()\n",
    "\n",
    "print('{} bytes; UTF-8 characters'.format(num_bytes, num_chars))\n",
    "\n",
    "# final character takes up 4 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Substrings - tf.strings.substr operation accepts unit parameter\n",
    "* used to determine what kind of offsets, contained by the 'pos' and 'len' parameters\n",
    "* DEFAULT - unit=BYTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0\\x9f\\x98\\x8a'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Unicode Strings\n",
    "* tf.strings.unicode_split - splits unicode strings into substrings of individual characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte Offsets for Characters\n",
    "* to align the character string (generated by tf.strings.unicode_decode) with the original string - helpful to know the Offset (for where each charcter begins)\n",
    "* tf.strings.unicode_decode_with_offsets is similar (to unicode_decode) - but returns a 2nd tensor (containing start offsets of each character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint127880\n",
      "At byte offset 4: codepoint127881\n",
      "At byte offset 8: codepoint127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"üéàüéâüéä\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print(\"At byte offset {}: codepoint{}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode Scripts\n",
    "* each unicode code point - belongs to a single collection of codepoints - known as a Script\n",
    "* character's Script - helpful in determining which language character may belong in\n",
    "* tf.strings.unicode_script - determines which script a given codepoint uses\n",
    "\n",
    "#### Script codes are int32 values - corresponding to International Components for Unicode (ICU) UScriptCode values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])\n",
    "\n",
    "print(uscript.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [33464, 1041] ['Ëä∏', '–ë'] \n",
    "# [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.strings.unicode_script - can be applied to multidimensional tf.Tensors or tf.RaggedTensors (of codepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Simple Segmentation\n",
    "### Segmentation - task of splitting text into word-like units\n",
    "* in web text, different languages and scripts are frequently mixed together\n",
    "* rough segmentation (without ML) can be performed - using changes in script to approximate word boundaries\n",
    "* This will work for most languages that use Spaces (space characters all classified as USCRIPT_COMMON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype - string; shape - [num_sentences]\n",
    "\n",
    "sentence_texts = [u'Hello, world.', u'‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode the sentences into character codepoints - Find the script Identifier for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype - int32; shape - [num_sentences, (num_chars_per_sentence)]\n",
    "\n",
    "# sentence_char_codepoint[i, j] - codepoint for jth character - in ith sentence\n",
    "\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# same as above\n",
    "\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Script Identifiers\n",
    "* determine where word boundaries should be added\n",
    "* add a word boundary at beginning of each sentence - and for each character whose script differs from previous character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype - bool; shape - [num_sentences, (num_chars_per_sentence)]\n",
    "\n",
    "# sentence_char-starts_word[i, j] - True, if jth character in ith sentence, starts a word\n",
    "\n",
    "sentence_char_starts_word = tf.concat([tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "                                      tf.not_equal(sentence_char_script[:, 1:], \n",
    "                                                   sentence_char_script[:, :-1])],\n",
    "                                     axis=1)\n",
    "\n",
    "\n",
    "# dtype - int64; shape - [num_words]\n",
    "\n",
    "# word_starts[i] - index, of character starting the ith word - in flattened list of all chars\n",
    "\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use these Start Offsets - to build a RaggedTensor - containing list of words from all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype - int32; shape - [num_words, (num_chars_per_word)]\n",
    "\n",
    "# word_char_codepoint[i, j] - codepoint for jth character in ith word\n",
    "\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(values = sentence_char_codepoint.values,\n",
    "                                                     row_starts = word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, Segment the word codepoints RaggedTensor - back into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype - int64; shape - [num_sentences]\n",
    "\n",
    "# sentence_num_words[i] - number of words in ith sentence\n",
    "\n",
    "sentence_num_words = tf.reduce_sum(tf.cast(sentence_char_starts_word, tf.int64),\n",
    "                                  axis=1)\n",
    "\n",
    "# dtype - int32; shape - [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "\n",
    "# sentence_word_char_codepoint[i, j, k] - is codepoint for kth character, in jth word, in \n",
    "# ith sentence\n",
    "\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(values = word_char_codepoint,\n",
    "                                                               row_lengths = sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Result - can be made easier to read - by Encoding back into UTF-8 strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
