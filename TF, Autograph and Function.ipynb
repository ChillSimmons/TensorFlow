{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 alpha - tf.function\n",
    "### Tool for making Graphs out of programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a Function is like an operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a,b) :\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2,2]), tf.ones([2,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions have Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a,b):\n",
    "    return a+b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can use Functions, inside Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=74, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "    return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3,2]), tf.ones([2,2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism\n",
    "#### tf.function can be as flexible and generic as python functions\n",
    "#### Call a function with arguments of different type - Functions are Polymorphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 tf.Tensor(2, shape=(), dtype=int32)\n",
      "add 1.1 tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "add string tensor tf.Tensor(b'aa', shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(), dtype=string, numpy=b'aa'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a):\n",
    "    return a+a\n",
    "\n",
    "print('add 1', add(1))\n",
    "print('add 1.1', add(1.1))\n",
    "print('add string tensor', add(tf.constant('a')))\n",
    "\n",
    "c = add.get_concrete_function(tf.TensorSpec(shape=None, dtype=tf.string))\n",
    "c(a = tf.constant('a')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions can be Faster than eager code - for Graphs with small operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.8870195341296494\n",
      "Function conv: 0.7944547641091049\n",
      "\n",
      "Note how there's not much difference in performance for convolutions\n",
      "\n",
      "Eager lstm: 0.04588328907266259\n",
      "Function lstm: 0.003938127309083939\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "\n",
    "conv_layer(image); conv_fn(image)\n",
    "\n",
    "print('Eager conv:', timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print('Function conv:', timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print()\n",
    "print(\"Note how there's not much difference in performance for convolutions\")\n",
    "print()\n",
    "\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "    return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10,10])\n",
    "state = [tf.zeros([10,10])] * 2\n",
    "\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "\n",
    "print('Eager lstm:', timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print('Function lstm:', timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State in tf.function\n",
    "#### There is no need to add manual control dependencies - tf.function can handle the intended execution order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3083, shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "    a.assign(y*b)\n",
    "    b.assign_add(x*a)\n",
    "    return a+b\n",
    "\n",
    "f(1.0, 2.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "#### Downside - with ambiguous code, different behavior can occur with multiple eager calls leading to over-evaluation of output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.function-decorated function tried to create variables on non-first call.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-01a94a04a122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Broken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_canonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[1;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1513\u001b[0m         self._function_attributes)\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    692\u001b[0m                                           converted_func)\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m               ), args, kwargs)\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fn/10dyfg195751k6kfky4t_j7r0000gn/T/tmpg2vnexkx.py\u001b[0m in \u001b[0;36mtf__f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Variable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assign_add'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently whitelisted: %s: constructor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;31m# Other built-in modules are permanently whitelisted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;34m\"\"\"To avoid capturing loop variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36minvalid_creator_scope\u001b[0;34m(*unused_args, **unused_kwds)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;34m\"\"\"Disables variable creation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m       raise ValueError(\n\u001b[0;32m--> 375\u001b[0;31m           \u001b[0;34m\"tf.function-decorated function tried to create \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m           \"variables on non-first call.\")\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tf.function-decorated function tried to create variables on non-first call."
     ]
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    v = tf.Variable(1.0)\n",
    "    v.assign_add(x)\n",
    "    return v\n",
    "\n",
    "f(1.)                 # Broken - Leads to ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeatedly evaluating the Tensor obtained from f(1.) - in a graph context, causes you to get increasing numbers\n",
    "#### tf.function does not allow this - NON-ambiguous code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    return v.assign_add(x)\n",
    "\n",
    "print(f(1.0)),\n",
    "print(f(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables can be created Inside Functions - ONLY if, the variable is executed once, upon initial Function execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class C: pass\n",
    "obj = C(); obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "    if obj.v is None:\n",
    "        obj.v = tf.Variable(1.0)\n",
    "    return obj.v.assign_add(x)\n",
    "\n",
    "print(g(1.0)),\n",
    "print(g(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Initializers - can depend on Function arguments, or on other variables\n",
    "#### Figure out the right Initialization Order - using same method to generate Control Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0411 19:46:03.033680 140736985473984 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0xb32203638> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
      "W0411 19:46:03.041373 140736985473984 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0xb322ae0e8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <method-wrapper '__call__' of weakref object at 0xb32203638> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
      "WARNING: Entity <method-wrapper '__call__' of weakref object at 0xb322ae0e8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3309, shape=(), dtype=float32, numpy=36.0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = []\n",
    "\n",
    "@tf.function\n",
    "def fn(x):\n",
    "    if not state:\n",
    "        state.append(tf.Variable(2.0 * x))\n",
    "        state.append(tf.Variable(state[0] * 3.0))\n",
    "    return state[0] * x * state[1]\n",
    "\n",
    "fn(tf.constant(1.0))\n",
    "fn(tf.constant(3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Flow and Autograph\n",
    "#### tf.cond and tf.while_loop will work with tf.function\n",
    "#### plus, the AUTOGRAPH library - will rewrite conditionals and loops, which depend on Tensors to run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.418310046 0.128251672 0.0406667 ... 0.480195522 0.935450315 0.897618651]\n",
      "[0.395505756 0.127553076 0.0406442918 ... 0.446400195 0.733124912 0.715136409]\n",
      "[0.376096964 0.126865789 0.0406219214 ... 0.418935478 0.624973476 0.613887668]\n",
      "[0.35931313 0.1261895 0.0405995883 ... 0.396033227 0.554581344 0.546857953]\n",
      "[0.344608843 0.125523925 0.0405772962 ... 0.376549721 0.503945947 0.498161614]\n",
      "[0.331585735 0.12486878 0.0405550338 ... 0.359707326 0.465214729 0.460670143]\n",
      "[0.319944859 0.124223806 0.0405328088 ... 0.344956189 0.434324801 0.430630237]\n",
      "[0.309457064 0.123588733 0.0405106209 ... 0.331894845 0.408929229 0.405847877]\n",
      "[0.299943089 0.122963309 0.0404884703 ... 0.320222348 0.387563139 0.384941489]\n",
      "[0.291260511 0.122347288 0.0404663607 ... 0.30970794 0.36925751 0.366991162]\n",
      "[0.283294529 0.121740438 0.040444281 ... 0.300171345 0.353342086 0.351357073]\n",
      "[0.275951475 0.121142536 0.0404222421 ... 0.291469395 0.339336127 0.337578475]\n",
      "[0.269153923 0.120553367 0.0404002368 ... 0.283486664 0.326884598 0.325313807]\n",
      "[0.26283738 0.119972713 0.0403782688 ... 0.276128978 0.315718681 0.314303726]\n",
      "[0.256947488 0.119400389 0.0403563343 ... 0.269318581 0.305630624 0.304347277]\n",
      "[0.2514382 0.118836194 0.0403344408 ... 0.262990624 0.296456903 0.295285881]\n",
      "[0.24627009 0.118279934 0.040312577 ... 0.257090598 0.288066834 0.28699261]\n",
      "[0.241409287 0.117731415 0.0402907506 ... 0.251572251 0.280354559 0.279364437]\n",
      "[0.236826435 0.117190465 0.0402689576 ... 0.24639602 0.273233205 0.272316724]\n",
      "[0.232495949 0.116656914 0.0402472019 ... 0.24152787 0.266630739 0.265779227]\n",
      "[0.228395417 0.116130576 0.0402254798 ... 0.236938342 0.260486931 0.259693027]\n",
      "[0.224505171 0.115611315 0.0402037911 ... 0.232601762 0.254750907 0.254008353]\n",
      "[0.220807791 0.115098953 0.0401821397 ... 0.228495732 0.249379337 0.248682827]\n",
      "[0.217287838 0.114593349 0.0401605256 ... 0.224600419 0.24433513 0.243680075]\n",
      "[0.213931531 0.114094354 0.0401389413 ... 0.22089839 0.239586234 0.2389687]\n",
      "[0.210726514 0.113601826 0.0401173942 ... 0.217374161 0.235104874 0.234521374]\n",
      "[0.207661778 0.113115624 0.0400958806 ... 0.214013875 0.23086679 0.230314314]\n",
      "[0.204727337 0.112635635 0.0400744043 ... 0.210805207 0.226850688 0.22632657]\n",
      "[0.201914221 0.112161703 0.0400529616 ... 0.207737073 0.223037794 0.222539693]\n",
      "[0.19921425 0.111693703 0.0400315486 ... 0.204799488 0.219411522 0.218937337]\n",
      "[0.196620047 0.111231521 0.0400101729 ... 0.201983422 0.21595709 0.215504974]\n",
      "[0.194124877 0.110775046 0.0399888344 ... 0.199280724 0.212661311 0.212229624]\n",
      "[0.191722557 0.110324144 0.0399675258 ... 0.196683943 0.209512398 0.209099606]\n",
      "[0.189407483 0.109878697 0.0399462543 ... 0.19418636 0.206499726 0.206104517]\n",
      "[0.187174514 0.109438613 0.0399250165 ... 0.191781789 0.203613713 0.203234896]\n",
      "[0.185018852 0.109003767 0.0399038084 ... 0.189464599 0.200845748 0.200482175]\n",
      "[0.182936162 0.108574092 0.0398826413 ... 0.187229604 0.198187962 0.197838634]\n",
      "[0.180922404 0.108149461 0.0398615077 ... 0.185072064 0.195633233 0.195297271]\n",
      "[0.178973868 0.107729763 0.0398404077 ... 0.182987601 0.193175063 0.192851618]\n",
      "[0.177087083 0.107314914 0.0398193374 ... 0.180972174 0.190807506 0.190495819]\n",
      "[0.17525886 0.106904827 0.0397983 ... 0.179022029 0.18852511 0.18822448]\n",
      "[0.173486233 0.106499404 0.0397772975 ... 0.177133739 0.186322883 0.186032668]\n",
      "[0.17176643 0.10609857 0.0397563279 ... 0.175304085 0.184196264 0.183915883]\n",
      "[0.170096859 0.105702236 0.0397353917 ... 0.173530087 0.182140991 0.181869879]\n",
      "[0.168475151 0.105310313 0.0397144891 ... 0.171808973 0.180153176 0.179890841]\n",
      "[0.16689904 0.104922719 0.0396936201 ... 0.17013818 0.178229183 0.177975163]\n",
      "[0.165366426 0.104539365 0.0396727808 ... 0.16851528 0.176365659 0.176119521]\n",
      "[0.163875341 0.10416019 0.039651975 ... 0.166938052 0.174559504 0.174320862]\n",
      "[0.162423968 0.103785113 0.0396312065 ... 0.165404379 0.172807842 0.172576293]\n",
      "[0.161010548 0.103414074 0.0396104716 ... 0.163912266 0.171107978 0.170883194]\n",
      "[0.159633443 0.103046991 0.0395897664 ... 0.162459895 0.169457376 0.169239059]\n",
      "[0.158291131 0.102683775 0.0395690911 ... 0.161045536 0.167853743 0.167641565]\n",
      "[0.156982183 0.102324389 0.0395484492 ... 0.159667552 0.166294873 0.166088566]\n",
      "[0.155705228 0.10196875 0.0395278409 ... 0.158324406 0.164778724 0.164578]\n",
      "[0.154459 0.1016168 0.0395072624 ... 0.157014638 0.16330336 0.163108]\n",
      "[0.15324226 0.101268478 0.0394867174 ... 0.155736893 0.161867008 0.161676764]\n",
      "[0.152053878 0.100923702 0.0394662023 ... 0.154489905 0.160467952 0.160282612]\n",
      "[0.150892764 0.100582428 0.0394457243 ... 0.15327245 0.15910463 0.158923969]\n",
      "[0.149757877 0.100244597 0.0394252725 ... 0.152083367 0.157775521 0.157599375]\n",
      "[0.148648247 0.0999101326 0.0394048542 ... 0.150921583 0.156479225 0.156307414]\n",
      "[0.147562981 0.0995790064 0.0393844694 ... 0.149786055 0.155214429 0.155046746]\n",
      "[0.146501169 0.0992511585 0.0393641144 ... 0.148675814 0.153979853 0.153816149]\n",
      "[0.145461962 0.0989265293 0.0393437929 ... 0.147589937 0.152774319 0.15261443]\n",
      "[0.144444615 0.0986050665 0.0393235 ... 0.146527529 0.15159671 0.151440486]\n",
      "[0.143448353 0.0982867107 0.0393032394 ... 0.145487785 0.150445968 0.150293276]\n",
      "[0.142472446 0.0979714245 0.0392830111 ... 0.144469887 0.149321079 0.149171785]\n",
      "[0.141516209 0.0976591632 0.0392628126 ... 0.143473104 0.148221076 0.148075059]\n",
      "[0.140579015 0.0973498747 0.0392426476 ... 0.14249669 0.147145078 0.14700222]\n",
      "[0.139660209 0.0970435 0.0392225124 ... 0.141539961 0.146092191 0.145952389]\n",
      "[0.138759196 0.0967400074 0.039202407 ... 0.140602291 0.145061642 0.144924775]\n",
      "[0.137875438 0.0964393392 0.0391823314 ... 0.139683023 0.144052625 0.143918589]\n",
      "[0.137008354 0.0961414576 0.0391622894 ... 0.138781577 0.143064409 0.1429331]\n",
      "[0.136157453 0.0958463252 0.0391422771 ... 0.137897387 0.142096266 0.14196761]\n",
      "[0.135322243 0.0955539 0.0391223 ... 0.137029901 0.141147554 0.14102146]\n",
      "[0.134502232 0.0952641219 0.0391023494 ... 0.136178613 0.140217602 0.140094]\n",
      "[0.133696958 0.0949769765 0.0390824303 ... 0.135343 0.13930583 0.139184624]\n",
      "[0.132906 0.094692409 0.039062541 ... 0.134522602 0.138411626 0.138292745]\n",
      "[0.132128924 0.0944103897 0.0390426815 ... 0.133716971 0.13753444 0.137417808]\n",
      "[0.131365344 0.0941308737 0.0390228517 ... 0.132925645 0.136673748 0.136559308]\n",
      "[0.130614862 0.0938538238 0.0390030518 ... 0.132148221 0.135829046 0.135716707]\n",
      "[0.129877105 0.0935792103 0.0389832817 ... 0.131384298 0.134999827 0.134889528]\n",
      "[0.129151732 0.0933069959 0.0389635414 ... 0.130633488 0.134185642 0.134077311]\n",
      "[0.128438398 0.0930371433 0.0389438346 ... 0.129895419 0.133386016 0.133279607]\n",
      "[0.127736762 0.0927696154 0.0389241539 ... 0.129169747 0.132600531 0.132495984]\n",
      "[0.127046511 0.0925043896 0.038904503 ... 0.128456101 0.13182877 0.131726056]\n",
      "[0.126367331 0.0922414288 0.0388848819 ... 0.127754152 0.131070346 0.13096942]\n",
      "[0.125698954 0.0919806883 0.0388652906 ... 0.127063617 0.1303249 0.130225673]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3354, shape=(10,), dtype=float32, numpy=\n",
       "array([0.12504108, 0.09172215, 0.03884573, 0.01900934, 0.08868066,\n",
       "       0.12045684, 0.12810788, 0.12638417, 0.12959203, 0.12949447],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "f(tf.random.uniform([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the code Autograph generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\n",
      "\n",
      "def tf__f(x):\n",
      "  try:\n",
      "    with ag__.function_scope('f'):\n",
      "      do_return = False\n",
      "      retval_ = None\n",
      "\n",
      "      def loop_test(x_1):\n",
      "        with ag__.function_scope('loop_test'):\n",
      "          return ag__.gt(ag__.converted_call('reduce_sum', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x_1,), {}), 1)\n",
      "\n",
      "      def loop_body(x_1):\n",
      "        with ag__.function_scope('loop_body'):\n",
      "          with ag__.utils.control_dependency_on_returns(ag__.converted_call('print', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x_1,), {})):\n",
      "            x, tf_1 = ag__.utils.alias_tensors(x_1, tf)\n",
      "            x = ag__.converted_call('tanh', tf_1, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x,), {})\n",
      "            return x,\n",
      "      x, = ag__.while_stmt(loop_test, loop_body, (x,), (tf, x, ag__))\n",
      "      do_return = True\n",
      "      retval_ = x\n",
      "      return retval_\n",
      "  except:\n",
      "    ag__.rewrite_graph_construction_error(ag_source_map__)\n",
      "\n",
      "\n",
      "\n",
      "tf__f.autograph_info__ = {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling Autograph\n",
    "#### It only affects basic Control Flow constructs in python (if, while, for, etc.) - Only changing them, if the predicates are Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-bfcdc0e4d7b8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-bfcdc0e4d7b8>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for i in tf.range(10):       # depends on a Tensor - will be converted\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    for i in range(10):          # static python loop - unrolled, no conversion\n",
    "        do_stuff()\n",
    "    for i in tf.range(10):       # depends on a Tensor - will be converted\n",
    "\n",
    "    \n",
    "# Will Get ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In addition, Guarantee prints and asserts happen dynamically - using tf.print, and tf.assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3417, shape=(), dtype=int32, numpy=10240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    for i in tf.range(10):\n",
    "        tf.print(i)\n",
    "        tf.Assert(i < 10, ['a'])\n",
    "        x += x\n",
    "    return x\n",
    "\n",
    "f(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograph cannot compile python into TF Graphs - data structures, to be used dynamically, Must be TensorFlow data structures\n",
    "### tf.TensorArray \n",
    "#### This method would be best to accumulate data in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3486, shape=(10,), dtype=float32, numpy=\n",
       "array([   20.,    40.,    80.,   160.,   320.,   640.,  1280.,  2560.,\n",
       "        5120., 10240.], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    ta = tf.TensorArray(tf.float32, size=10)\n",
    "    for i in tf.range(10):\n",
    "        x += x\n",
    "        ta = ta.write(i, x)\n",
    "    return ta.stack()\n",
    "\n",
    "f(10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "### Functions can give the runtime more information about what was the intended behavior of the code. tf.function is capable of adding the minimal set of necessary Control Dependencies for the code to run correctly. Often for certain dynamic operations, Autograph (fully integrated library with tf.function) requires TensorFlow data structures (tf._)_ rather than simple python structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
